{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "975ce6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c9a3f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\adity\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\adity\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091eba10",
   "metadata": {},
   "source": [
    "# Analysis of Readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f3b5c6",
   "metadata": {},
   "source": [
    "All the related fields such as complex words,syllable count etc are calculated in the functions of format \"func_name_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7122f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syllables_1(word):\n",
    "    vowels = 'aeiouy'\n",
    "    count = 0\n",
    "\n",
    "    for letter in word:\n",
    "        if letter.lower() in vowels:\n",
    "            count += 1\n",
    "\n",
    "    if count > 1 and word.endswith(('es', 'ed')):\n",
    "        count -= 1\n",
    "\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c5be278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_1(text):\n",
    "    words = word_tokenize(text)\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    num_words = len(words)\n",
    "    num_sentences = len(sentences)\n",
    "\n",
    "    complex_words = [word for word in words if count_syllables_1(word) > 2]\n",
    "    num_complex_words = len(complex_words)\n",
    "\n",
    "    syllable_count_per_word = sum(count_syllables_1(word) for word in words) / num_words\n",
    "\n",
    "    average_sentence_length = num_words / num_sentences\n",
    "    percentage_complex_words = num_complex_words / num_words * 100\n",
    "    fog_index = 0.4 * (average_sentence_length + percentage_complex_words)\n",
    "\n",
    "    return {\n",
    "        'Average Sentence Length': average_sentence_length,\n",
    "        'Percentage of Complex Words': percentage_complex_words,\n",
    "        'Fog Index': fog_index,\n",
    "        'Count of Complex Words': num_complex_words,\n",
    "        'Syllable Count Per Word': syllable_count_per_word\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1c5841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text_files_1(folder_path):\n",
    "    result_data = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.txt'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "                metrics = calculate_metrics_1(text)\n",
    "                result_data.append({'File': file_name, **metrics})\n",
    "\n",
    "    result_df = pd.DataFrame(result_data)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58310f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "722ee881",
   "metadata": {},
   "source": [
    "Personal Pronoun Counts,Average Word Length calculated in functions of format \"func_name_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f1561ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_personal_pronouns_2(text):\n",
    "    personal_pronouns = [\"I\", \"we\", \"my\", \"ours\", \"us\",\"We\",\"My\",\"Ours\",\"Us\"]\n",
    "    pronoun_counts = {pronoun: text.count(pronoun) for pronoun in personal_pronouns}\n",
    "    pronoun_counts[\"us\"] -= text.lower().count(\"us\")\n",
    "    \n",
    "    return pronoun_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d5341f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_2(text):\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    personal_pronoun_counts = count_personal_pronouns_2(text)\n",
    "\n",
    "    total_characters = sum(len(word) for word in words)\n",
    "    total_words = len(words)\n",
    "    average_word_length = total_characters / total_words if total_words > 0 else 0\n",
    "\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        'Personal Pronoun Counts': personal_pronoun_counts,\n",
    "        'Average Word Length': average_word_length\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "47c45cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text_files_2(folder_path):\n",
    "    result_data = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.txt'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "                metrics = calculate_metrics_2(text)\n",
    "                result_data.append({'File': file_name, **metrics})\n",
    "\n",
    "    result_df = pd.DataFrame(result_data)\n",
    "    \n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e62a97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "250c214a",
   "metadata": {},
   "source": [
    "Calculating clean words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1acd7617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cleaned_word_count_3(text):\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    cleaned_words = [word.lower() for word in words if word.lower() not in stop_words and word not in string.punctuation]\n",
    "    word_count = len(cleaned_words)\n",
    "\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "158feab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def analyze_text_files_3(folder_path):\n",
    "    result_data = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.txt'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "                word_count = calculate_cleaned_word_count_3(text)\n",
    "                \n",
    "                result_data.append({'File': file_name, 'Cleaned Word Count': word_count})\n",
    "\n",
    "    result_df = pd.DataFrame(result_data)\n",
    "    return result_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d300c503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a43981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b41ea0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Percentage of Complex Words</th>\n",
       "      <th>Fog Index</th>\n",
       "      <th>Count of Complex Words</th>\n",
       "      <th>Syllable Count Per Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign_blackassign0001.txt</td>\n",
       "      <td>22.323944</td>\n",
       "      <td>20.694006</td>\n",
       "      <td>17.207180</td>\n",
       "      <td>328</td>\n",
       "      <td>1.663722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign_blackassign0002.txt</td>\n",
       "      <td>23.728395</td>\n",
       "      <td>27.627471</td>\n",
       "      <td>20.542347</td>\n",
       "      <td>531</td>\n",
       "      <td>1.855359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign_blackassign0003.txt</td>\n",
       "      <td>24.032787</td>\n",
       "      <td>32.810368</td>\n",
       "      <td>22.737262</td>\n",
       "      <td>481</td>\n",
       "      <td>1.995225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign_blackassign0004.txt</td>\n",
       "      <td>26.035714</td>\n",
       "      <td>31.618656</td>\n",
       "      <td>23.061748</td>\n",
       "      <td>461</td>\n",
       "      <td>1.955418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign_blackassign0005.txt</td>\n",
       "      <td>22.977273</td>\n",
       "      <td>27.299703</td>\n",
       "      <td>20.110790</td>\n",
       "      <td>276</td>\n",
       "      <td>1.838773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>blackassign_blackassign0096.txt</td>\n",
       "      <td>27.018519</td>\n",
       "      <td>25.222755</td>\n",
       "      <td>20.896510</td>\n",
       "      <td>368</td>\n",
       "      <td>1.823852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>blackassign_blackassign0097.txt</td>\n",
       "      <td>33.767442</td>\n",
       "      <td>21.556474</td>\n",
       "      <td>22.129566</td>\n",
       "      <td>313</td>\n",
       "      <td>1.645317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>blackassign_blackassign0098.txt</td>\n",
       "      <td>46.777778</td>\n",
       "      <td>27.315914</td>\n",
       "      <td>29.637477</td>\n",
       "      <td>115</td>\n",
       "      <td>1.698337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>blackassign_blackassign0099.txt</td>\n",
       "      <td>25.848485</td>\n",
       "      <td>23.329426</td>\n",
       "      <td>19.671164</td>\n",
       "      <td>199</td>\n",
       "      <td>1.691676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>blackassign_blackassign0100.txt</td>\n",
       "      <td>36.742857</td>\n",
       "      <td>24.727838</td>\n",
       "      <td>24.588278</td>\n",
       "      <td>318</td>\n",
       "      <td>1.751166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               File  Average Sentence Length  \\\n",
       "0   blackassign_blackassign0001.txt                22.323944   \n",
       "1   blackassign_blackassign0002.txt                23.728395   \n",
       "2   blackassign_blackassign0003.txt                24.032787   \n",
       "3   blackassign_blackassign0004.txt                26.035714   \n",
       "4   blackassign_blackassign0005.txt                22.977273   \n",
       "..                              ...                      ...   \n",
       "93  blackassign_blackassign0096.txt                27.018519   \n",
       "94  blackassign_blackassign0097.txt                33.767442   \n",
       "95  blackassign_blackassign0098.txt                46.777778   \n",
       "96  blackassign_blackassign0099.txt                25.848485   \n",
       "97  blackassign_blackassign0100.txt                36.742857   \n",
       "\n",
       "    Percentage of Complex Words  Fog Index  Count of Complex Words  \\\n",
       "0                     20.694006  17.207180                     328   \n",
       "1                     27.627471  20.542347                     531   \n",
       "2                     32.810368  22.737262                     481   \n",
       "3                     31.618656  23.061748                     461   \n",
       "4                     27.299703  20.110790                     276   \n",
       "..                          ...        ...                     ...   \n",
       "93                    25.222755  20.896510                     368   \n",
       "94                    21.556474  22.129566                     313   \n",
       "95                    27.315914  29.637477                     115   \n",
       "96                    23.329426  19.671164                     199   \n",
       "97                    24.727838  24.588278                     318   \n",
       "\n",
       "    Syllable Count Per Word  \n",
       "0                  1.663722  \n",
       "1                  1.855359  \n",
       "2                  1.995225  \n",
       "3                  1.955418  \n",
       "4                  1.838773  \n",
       "..                      ...  \n",
       "93                 1.823852  \n",
       "94                 1.645317  \n",
       "95                 1.698337  \n",
       "96                 1.691676  \n",
       "97                 1.751166  \n",
       "\n",
       "[98 rows x 6 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dataframe_1 = analyze_text_files_1(folder_path)\n",
    "result_dataframe_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c43100d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Personal Pronoun Counts</th>\n",
       "      <th>Average Word Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign_blackassign0001.txt</td>\n",
       "      <td>{'I': 78, 'we': 10, 'my': 10, 'ours': 0, 'us':...</td>\n",
       "      <td>4.361514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign_blackassign0002.txt</td>\n",
       "      <td>{'I': 41, 'we': 18, 'my': 6, 'ours': 0, 'us': ...</td>\n",
       "      <td>4.907388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign_blackassign0003.txt</td>\n",
       "      <td>{'I': 23, 'we': 22, 'my': 2, 'ours': 1, 'us': ...</td>\n",
       "      <td>5.352660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign_blackassign0004.txt</td>\n",
       "      <td>{'I': 19, 'we': 9, 'my': 5, 'ours': 1, 'us': 0...</td>\n",
       "      <td>5.204390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign_blackassign0005.txt</td>\n",
       "      <td>{'I': 17, 'we': 10, 'my': 2, 'ours': 0, 'us': ...</td>\n",
       "      <td>4.974283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>blackassign_blackassign0096.txt</td>\n",
       "      <td>{'I': 21, 'we': 12, 'my': 5, 'ours': 0, 'us': ...</td>\n",
       "      <td>4.904044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>blackassign_blackassign0097.txt</td>\n",
       "      <td>{'I': 18, 'we': 16, 'my': 3, 'ours': 0, 'us': ...</td>\n",
       "      <td>4.369835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>blackassign_blackassign0098.txt</td>\n",
       "      <td>{'I': 15, 'we': 2, 'my': 4, 'ours': 0, 'us': 0...</td>\n",
       "      <td>4.684086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>blackassign_blackassign0099.txt</td>\n",
       "      <td>{'I': 27, 'we': 5, 'my': 2, 'ours': 0, 'us': 0...</td>\n",
       "      <td>4.452521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>blackassign_blackassign0100.txt</td>\n",
       "      <td>{'I': 20, 'we': 14, 'my': 4, 'ours': 1, 'us': ...</td>\n",
       "      <td>4.720840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               File  \\\n",
       "0   blackassign_blackassign0001.txt   \n",
       "1   blackassign_blackassign0002.txt   \n",
       "2   blackassign_blackassign0003.txt   \n",
       "3   blackassign_blackassign0004.txt   \n",
       "4   blackassign_blackassign0005.txt   \n",
       "..                              ...   \n",
       "93  blackassign_blackassign0096.txt   \n",
       "94  blackassign_blackassign0097.txt   \n",
       "95  blackassign_blackassign0098.txt   \n",
       "96  blackassign_blackassign0099.txt   \n",
       "97  blackassign_blackassign0100.txt   \n",
       "\n",
       "                              Personal Pronoun Counts  Average Word Length  \n",
       "0   {'I': 78, 'we': 10, 'my': 10, 'ours': 0, 'us':...             4.361514  \n",
       "1   {'I': 41, 'we': 18, 'my': 6, 'ours': 0, 'us': ...             4.907388  \n",
       "2   {'I': 23, 'we': 22, 'my': 2, 'ours': 1, 'us': ...             5.352660  \n",
       "3   {'I': 19, 'we': 9, 'my': 5, 'ours': 1, 'us': 0...             5.204390  \n",
       "4   {'I': 17, 'we': 10, 'my': 2, 'ours': 0, 'us': ...             4.974283  \n",
       "..                                                ...                  ...  \n",
       "93  {'I': 21, 'we': 12, 'my': 5, 'ours': 0, 'us': ...             4.904044  \n",
       "94  {'I': 18, 'we': 16, 'my': 3, 'ours': 0, 'us': ...             4.369835  \n",
       "95  {'I': 15, 'we': 2, 'my': 4, 'ours': 0, 'us': 0...             4.684086  \n",
       "96  {'I': 27, 'we': 5, 'my': 2, 'ours': 0, 'us': 0...             4.452521  \n",
       "97  {'I': 20, 'we': 14, 'my': 4, 'ours': 1, 'us': ...             4.720840  \n",
       "\n",
       "[98 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dataframe_2 = analyze_text_files_2(folder_path)\n",
    "result_dataframe_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7452c459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Cleaned Word Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign_blackassign0001.txt</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign_blackassign0002.txt</td>\n",
       "      <td>1044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign_blackassign0003.txt</td>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign_blackassign0004.txt</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign_blackassign0005.txt</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>blackassign_blackassign0096.txt</td>\n",
       "      <td>803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>blackassign_blackassign0097.txt</td>\n",
       "      <td>684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>blackassign_blackassign0098.txt</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>blackassign_blackassign0099.txt</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>blackassign_blackassign0100.txt</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               File  Cleaned Word Count\n",
       "0   blackassign_blackassign0001.txt                 794\n",
       "1   blackassign_blackassign0002.txt                1044\n",
       "2   blackassign_blackassign0003.txt                 826\n",
       "3   blackassign_blackassign0004.txt                 825\n",
       "4   blackassign_blackassign0005.txt                 566\n",
       "..                              ...                 ...\n",
       "93  blackassign_blackassign0096.txt                 803\n",
       "94  blackassign_blackassign0097.txt                 684\n",
       "95  blackassign_blackassign0098.txt                 249\n",
       "96  blackassign_blackassign0099.txt                 466\n",
       "97  blackassign_blackassign0100.txt                 683\n",
       "\n",
       "[98 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dataframe_3 = analyze_text_files_3(folder_path)\n",
    "result_dataframe_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c789ad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "common_column = 'File'\n",
    "merged_df = result_dataframe_1.merge(result_dataframe_2, on=common_column, how='outer')\n",
    "final_merged_df = merged_df.merge(result_dataframe_3, on=common_column, how='outer')\n",
    "\n",
    "# Assuming final_merged_df is your DataFrame\n",
    "final_merged_df.to_csv('file_2.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e4460b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d36dd68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
