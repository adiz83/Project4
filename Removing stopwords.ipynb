{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ac5a0c9",
   "metadata": {},
   "source": [
    "# PROCESSING_STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0fef50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f7b244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Currency file modified\n",
    "def process_currency(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='latin-1') as input_file:\n",
    "        lines = input_file.readlines()\n",
    "\n",
    "    modified_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        currency, country = [part.strip() for part in line.split('|')]\n",
    "        modified_lines.extend([currency.capitalize(), country.lower()])\n",
    "\n",
    "    modified_lines = [line.upper() for line in modified_lines]\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as output_file:\n",
    "        output_file.write('\\n'.join(modified_lines))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dba67c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging stopwords and converting them to lowercase\n",
    "def merge_stopword(stopword_folder, output_file):\n",
    "    merged_stopwords = set()\n",
    "\n",
    "    for filename in os.listdir(stopword_folder):\n",
    "        file_path = os.path.join(stopword_folder, filename)\n",
    "\n",
    "        if os.path.isfile(file_path):\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    stopwords = set(file.read().split())\n",
    "                    merged_stopwords.update(stopwords)\n",
    "            except Exception as e:\n",
    "                print(f\"Error opening file {filename}: {e}\")\n",
    "\n",
    "    merged_stopwords = [word.lower() for word in merged_stopwords]\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as output_file:\n",
    "        output_file.write('\\n'.join(merged_stopwords))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e43414f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'StopWords_Currencies.txt'\n",
    "output_file = 'stopword_currencies_modified.txt' \n",
    "process_currency(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3aca3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_folder = 'stopwords' \n",
    "output_file = 'merged_stopwords.txt' \n",
    "merge_stopword(stopword_folder, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f9b24a",
   "metadata": {},
   "source": [
    "# Converting text documents to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb7bce86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_lowercase(input_folder, output_folder):\n",
    "    \n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        input_file_path = os.path.join(input_folder, filename)\n",
    "        output_file_path = os.path.join(output_folder, filename)\n",
    "\n",
    "        with open(input_file_path, 'r', encoding='utf-8') as input_file:\n",
    "            content = input_file.read()\n",
    "\n",
    "        #To lowercase\n",
    "        modified_content = content.lower()\n",
    "\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "            output_file.write(modified_content)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8390030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder_path = 'output'\n",
    "output_folder_path = 'output_lowercase'\n",
    "\n",
    "convert_to_lowercase(input_folder_path, output_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94afca04",
   "metadata": {},
   "source": [
    "# Removing Stopwords from Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b812aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stopwords(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        stopwords = set(file.read().split())\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8247e4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_from_file(input_file_path, stopwords):\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as input_file:\n",
    "        content = input_file.read()\n",
    "\n",
    "    words = word_tokenize(content)\n",
    "    filtered_words = [word for word in words if word.lower() not in stopwords]\n",
    "\n",
    "    return ' '.join(filtered_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "867a9862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_output_folder(input_folder, output_folder, stopwords):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename == '.ipynb_checkpoints':\n",
    "            continue\n",
    "\n",
    "        input_file_path = os.path.join(input_folder, filename)\n",
    "        output_file_path = os.path.join(output_folder, filename)\n",
    "\n",
    "        modified_content = remove_stopwords_from_file(input_file_path, stopwords)\n",
    "\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "            output_file.write(modified_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ce251db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stopwords_file_path = 'merged_stopwords.txt'\n",
    "input_folder_path = 'output_lowercase'\n",
    "output_folder_path = 'output_no_stopwords'\n",
    "\n",
    "stopwords = read_stopwords(stopwords_file_path)\n",
    "\n",
    "process_output_folder(input_folder_path, output_folder_path, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d3fdcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2e41d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2040d341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6206159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c368628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c477427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
